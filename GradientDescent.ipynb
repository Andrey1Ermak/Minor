{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (y_i - (\\theta_0 + \\theta_1 x_i))^2$$\n",
    "\n",
    "$$\\frac{\\partial \\text{MSE}}{\\partial \\theta_0} = -\\frac{2}{m} \\sum_{i=1}^m (y_i - (\\theta_0 + \\theta_1 x_i))$$\n",
    "$$\\frac{\\partial \\text{MSE}}{\\partial \\theta_1} = -\\frac{2}{m} \\sum_{i=1}^m (y_i - (\\theta_0 + \\theta_1 x_i)) x_i$$\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\cdot \\frac{\\partial \\text{MSE}}{\\partial \\theta_j}$$\n",
    "$\\alpha$ — learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(450) \n",
    "x = np.random.rand(10000)\n",
    "y = 2 * x + 1 + np.random.randn(10000) * 0.2\n",
    "\n",
    "theta_0 = 0.0\n",
    "theta_1 = 0.0\n",
    "alpha = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "m = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: MSE = 4.3779, theta_0 = 0.0400, theta_1 = 0.0233\n",
      "Iteration 500: MSE = 0.0691, theta_0 = 1.3180, theta_1 = 1.4077\n",
      "Final parameters: theta_0 = 1.1669, theta_1 = 1.6899\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(num_iterations):\n",
    "    y_pred = theta_0 + theta_1 * x\n",
    "    \n",
    "    error = y - y_pred\n",
    "    \n",
    "    grad_theta_0 = -2 / m * np.sum(error)\n",
    "    grad_theta_1 = -2 / m * np.sum(error * x)\n",
    "    \n",
    "    theta_0 -= alpha * grad_theta_0\n",
    "    theta_1 -= alpha * grad_theta_1\n",
    "    \n",
    "    if iteration % 500 == 0:\n",
    "        mse = np.mean(error**2)\n",
    "        print(f\"Iteration {iteration}: MSE = {mse:.4f}, theta_0 = {theta_0:.4f}, theta_1 = {theta_1:.4f}\")\n",
    "\n",
    "print(f\"Final parameters: theta_0 = {theta_0:.4f}, theta_1 = {theta_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n",
    "\n",
    "$$\\text{Log Loss} = -\\frac{1}{m} \\sum_{i=1}^m \\left( y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right)$$\n",
    "\n",
    "$$\\hat{y}_i = \\sigma(z_i) = \\frac{1}{1 + e^{-(\\theta_0 + \\theta_1 x_i)}}$$\n",
    " \n",
    "$$\\frac{\\partial \\text{Log Loss}}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}_i - y_i)$$\n",
    "\n",
    "$$\\frac{\\partial \\text{Log Loss}}{\\partial \\theta_1} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}_i - y_i) x_i$$\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\cdot \\frac{\\partial \\text{Log Loss}}{\\partial \\theta_j}$$\n",
    "$\\alpha$ — learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100) \n",
    "y = (x > 0.5).astype(int) \n",
    "\n",
    "theta_0 = 0.0 \n",
    "theta_1 = 0.0  \n",
    "alpha = 0.1  \n",
    "num_iterations = 1000  \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Log Loss = 0.6931, theta_0 = -0.0030, theta_1 = 0.0116\n",
      "Iteration 500: Log Loss = 0.3569, theta_0 = -1.7200, theta_1 = 3.6188\n",
      "Final parameters: theta_0 = -2.6841, theta_1 = 5.5676\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(num_iterations):\n",
    "    z = theta_0 + theta_1 * x\n",
    "    y_pred = sigmoid(z)\n",
    "    \n",
    "    grad_theta_0 = np.mean(y_pred - y)\n",
    "    grad_theta_1 = np.mean((y_pred - y) * x)\n",
    "    \n",
    "    theta_0 -= alpha * grad_theta_0\n",
    "    theta_1 -= alpha * grad_theta_1\n",
    "    \n",
    "    if iteration % 500 == 0:\n",
    "        log_loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "        print(f\"Iteration {iteration}: Log Loss = {log_loss:.4f}, theta_0 = {theta_0:.4f}, theta_1 = {theta_1:.4f}\")\n",
    "\n",
    "print(f\"Final parameters: theta_0 = {theta_0:.4f}, theta_1 = {theta_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
