{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблема независимых бинарных классификаторов\n",
    "- Для каждой метки обучается отдельный бинарный классификатор\n",
    "- Игнорируются зависимости между метками.\n",
    "\n",
    "#### Classifier Chains (Цепочки классификаторов)\n",
    "- Каждая метка прогнозируется с учётом предыдущих меток.\n",
    "- Это позволяет учитывать зависимости между метками.\n",
    "\n",
    "#### Label Powerset\n",
    "- Каждая уникальная комбинация меток рассматривается как отдельный класс.\n",
    "- Подходит, если меток немного и их комбинации ограничены.\n",
    "\n",
    "#### Модели, поддерживающие мультилейбл классификацию напрямую\n",
    "- Деревья решений (с параметрами мультилейбл в Scikit-learn).\n",
    "- Алгоритмы, основанные на глубоких нейронных сетях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HammingLoss: 0.1870\n",
      "AUROC (macro): 0.8854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "X, Y = make_multilabel_classification(\n",
    "    n_samples=1000, n_features=20, n_classes=5, n_labels=2, random_state=42)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "base_model = RandomForestClassifier(random_state=42)\n",
    "chain_model = ClassifierChain(base_model, order='random', random_state=42)\n",
    "chain_model.fit(X_train, Y_train)\n",
    "\n",
    "probas = chain_model.predict_proba(X_test)\n",
    "predictions = (probas > 0.5).astype(int)\n",
    "\n",
    "hamming = hamming_loss(Y_test, predictions)\n",
    "print(f\"HammingLoss: {hamming:.4f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(Y_test, probas, average='macro')\n",
    "print(f\"AUROC (macro): {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3, Probability: 0.9800\n",
      "Label: 2, Probability: 0.2300\n",
      "Label: 5, Probability: 0.1000\n",
      "Label: 1, Probability: 0.0800\n",
      "Label: 4, Probability: 0.0700\n"
     ]
    }
   ],
   "source": [
    "probas_single = chain_model.predict_proba([X_test[0]])[0]\n",
    "top_10_indices = np.argsort(probas_single)[::-1][:10]\n",
    "top_10_labels = top_10_indices\n",
    "top_10_probabilities = probas_single[top_10_indices]\n",
    "\n",
    "label_names = ['1', '2', '3', '4', '5']\n",
    "top_10_named_labels = [label_names[idx] for idx in top_10_indices]\n",
    "\n",
    "for label, prob in zip(top_10_named_labels, top_10_probabilities):\n",
    "    print(f\"Label: {label}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
